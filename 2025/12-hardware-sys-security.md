- Hardware systems security (Dec 2025)
    - Compiler explorer
        - Pretty standard architecture with a frontend, Node.js servers, and a compilation queue processor that runs things in nsjail.
        - Compile workers have 4 TB of compilers installed on them, mounted on EFS.
        - Also, compilers require a lot of tiny runtime files, this is slow for EFS. To get around this, they build squashfs (compressed) images for each of those files in EFS, and then mount them on the workers as well, as loopback block device mounts — this prevents Linux from repeatedly doing metadata validity checks in NFS.
            - Pretty standard hack for reducing NFS latency: group your files into bigger chunks. And then set up read-only caching (à la JuiceFS or Modal).
        - Looks like they get about 3 req/s for compile, which is quite a fair bit! Not too much load though, so the support for a bajillion compilers is the main technical feat. Like serverless technology where you need to support a bunch of sparse endpoints.
        - Auto-scaling and caching, everything keeps costs down to $3000/mo, nice.
        - Seems super organic, nice to see a project grow and come about like this.
    - Figma's blog post on seccomp
        - Practical considerations on eng cost: "To create the seccomp allowlist, you need to either know all possible syscalls that the program can make, or more typically, empirically construct this list by running the program with a tool like `strace` on a representative corpus of inputs to exercise all possible codepaths."
        - seccomp allowlists may be brittle and need updates from people outside security org.
        - Can't dereference pointers in seccomp filters, so filtering openat() is impossible for instance as it takes a directory file descriptor.
        - They used nsjail and trialed pure-seccomp for their "RenderServer" (editor session backend) but ran into lots of edge cases in a production system.
        - Worth noting that seccomp itself is much faster, more lightweight than nsjail, easier to test.
        - Trick: Open all your files beforehand, then enter the sandbox.
    - Optimizing seccomp in gVisor
        - Small gains in seccomp-bpf by checking for non-cacheable syscalls first (Linux kernel emulates cacheable ones and stores them in a static map), and creating a binary tree instead of linear scan of jumps for instruction filtering.
        - They can also reduce code size with instruction-level optimizer. cBPF is limited to 4096 instructions, so this will allow them to add more rules in the future.
        - Remember that futex() is the most common syscall by far, followed by nanosleep and sendmmsg (for this distributed system I/O benchmark).
    - rust-vmm/seccompiler
        - Some more details on seccomp, installed via `prctl()` or `seccomp()`.
        - I searched this up a bit, once you enter seccomp mode on a process, you can't disable or relax it again. You can only install more filters with logical AND (stricter).
        - `seccomp()` is the modern API (Linux 3.17+), prctl is legacy cruft.
        - Didn't work in Orbstack, but i got it working in a quick [Codespace with this code](https://gist.github.com/ekzhang/12a0456a5e196375e76b06c7446191f9).
    - seL4
        - Three things that make it more expensive to develop: Microkernel, capability system, and formal verification. Formal verification is particularly costly, O(n^2) to lines of code.
        - Design principles are interesting: trying to be minimal, pragmatic (balancing systems concerns), not providing any hardware abstraction. But being correct in what it does support ("foundations for secure systems"), like a scheduler.
        - "Don't shoot yourself" not being a goal of the kernel, hmm…
        - Q: Are there capability-based systems that are not microkernels?
        - Capabilities versus ACLs, compare to Google Docs email sharing versus share links. Analogy holds but there are advantages to capabilities (transferability, cryptographic signing) and also to "traditional" ACL systems (auditability, know "who" / which user is accessing a resource is important).
    - Fuchsia
        - https://fuchsia.googlesource.com/fuchsia/+/refs/heads/main/zircon/kernel/ — Here is the main Ziron kernel source tree, seems to be written in C++. Standard OS kernel stuff here like a scheduler, spinlock and other components.
        - In the src/ folder there are the main user-space components outside of Zircon, these are written in Rust and C++. Since it's a microkernel, most of this is outside of Zircon.
        - Here is the ext4 file system entry point, it starts a "fidl" IPC server: https://fuchsia.googlesource.com/fuchsia/+/refs/heads/main/src/storage/ext4/server/src/main.rs
            - This is specified with a static CML file that has its manifest, what capabilities it uses: https://fuchsia.googlesource.com/fuchsia/+/refs/heads/main/src/storage/ext4/server/meta/ext4_readonly.cml?autodive=0%2F%2F
        - I guess you communicate between processes by listening on fidl channels. https://fuchsia.dev/fuchsia-src/get-started/learn/fidl/fidl
        - [Driver examples](https://fuchsia.dev/fuchsia-src/development/drivers/developer_guide/driver-examples) — looks like there's a "parent driver" and then child drivers, and then they can communicate with each other. Just hypothesizing, but there might be a board driver, and then it fans out with different memory regions allocated to child drivers that give each other appropriate capabilities / this limits surface area.
        - [Bootloader](https://fuchsia.googlesource.com/fuchsia/+/refs/heads/main/zircon/kernel/phys/physboot.cc) is called physboot, part of the Zircon kernel folder.
    - Moving on to the [Linux kernel hacker meets Fuchsia](https://a13xp0p0v.github.io/2022/05/24/pwn-fuchsia.html) blog post
        - Context: Fuchsia runs on Nest Hub devices. Development started in 2016.
        - There is "no concept of users," it's capability-based. Good diagram from the hacker blog post, summarizes which components live in Zircon. Note that seL4 also moves memory management out of the kernel (see discussion about page tables).
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fekzhang%2FTV1l9PtHYO.png?alt=media&token=b55b26c5-414e-442a-9e6a-ea484c37e15f)
        - "Finally, Fuchsia has an unusual scheme of software delivery and updating. Fuchsia components are identified by URLs and can be **resolved, downloaded, and executed on demand**. The main goal of this design solution is to make software packages in Fuchsia always up to date, like web pages."
        - Exploit of a "synthetic" use-after free vulnerability (PoC), talks about how he finds a way to exploit it in practice. Not a real zero-day but exploring the system, how you could exploit something if you had a real bug.
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fekzhang%2F-X2jkXMY9q.png?alt=media&token=434a65f1-20ce-4bce-abaa-d99072d63e9c)
        - "Heap spraying" as an attack vector to just randomly get access to the freed memory area and guess the kernel memory layout.
        - Lack of KASLR, easier to construct payloads due to static function offsets.
    - Holiday-time events
        - Chaos Computer Club in Boston
    - GPU confidential computing (2026)
        - In confidential computing, the memory encryption isn't the main point, it's having a memory region protections to ensure that only the guest can actually access certain portions of RAM. Also setting up encrypted channels from the client to the outside world (TLS).
        - Host is responsible for preventing VM from using too many resources, etc., but also it's part of the threat model!
        - Any time you have cryptography, you have side channels, so the host might be able to spy on the guest by using attacks like Spectre/Meltdown (speculative execution), or non-constant time operations that can leak small amounts of data about a secret.
        - The host is able to probe information about the cache of the guest at a very high granularity (even pausing each instruction), this is dangerous!
            - Adversary host could like, unmap all of the guest's pages and trigger a bunch of page faults, reveals data-dependent execution details of a server like vLLM that's running within the host. This could include user data.
        - Mitigations against Spectre, fencing after every conditional/indirect jump, are not great.
        - According to Tjaden the encryption is pretty junk. "If you put an interposer on the DRAM bus" then you can record traces with a trace analyzer and steal the root attestation key from the SGX enclave. (Not true of AMD though, the root computations run in a separate ARM64 processor embedded on the die using SRAM.)
            - Intel TDX = whole VM, while Intel SGX = inter-process secure enclave.
            - Chain of trust, need to inject CA into the code. Also there's a key with the device-specific key, organized by chip and firmware version, ratcheted on updates.
        - FHE - "You get all this __extra structure__. Extra structure is dangerous."
        - Bit error rates happen when GPUs are too hot, be careful!
        - General feeling is that all of the new components that Nvidia designed for the GPU-CC modules are a bit sketchy. People are skeptical about the security of the implementation of these complex protocols especially with side channels from a host adversary, and we'll see whether CC becomes more popular.
        - "It's the only way to get confidential GPU programming right now."
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fekzhang%2F999OKDk8bN.png?alt=media&token=d93340d1-0677-49ad-b6fd-e428af62d6a7)
        - Actual data in private memory is not encrypted, staging buffer between CVM (CPU enclave) and GPU is encrypted though. Until TDIS.
        - Recent blog posts from AWS about their evolution of Nitro, "more robust than other solutions right now" with formal verification and custom hardware support.
    - VFIO
        - This is a technology for presenting PCI devices to VMs.
        - IOMMU chip is able to isolate memory accesses from a device (device-specific address space), especially important for DMA — but also I/O access, interrupts.
        - VFIO Container > IOMMU Group > device.
            - Typically a VFIO container is like the isolation for a single VM.
        - A single group is hardware-enforced isolation (IOMMU feature), you need to get all the devices at once. Meanwhile, devices with page tables (host mapping) can access each other's memory through if they are in the same __VFIO container__ (shares page table).
        - You can speak directly to the device from a userspace device hypervisor like QEMU that emulate devices. It gets an interrupt from guest kernel -> host userspace control flow.
        - https://blog.aenix.io/the-evolution-of-network-virtualization-technologies-in-linux-6ba3a4e9f293
            - VFIO = direct device DMA passthrough to guest (virtio-pci) via IOMMU group isolation, host is not involved — what we were reading about
            - virtio = paravirtualized device drivers, e.g., virtio-net, virtio-blk, provides standardized interface for guest and host (virtqueue of ops from guest)
            - vhost = let the host kernel handle virtio requests (virtqueue) instead of implementing it yourself, e.g., vhost-net forwards directly. loses isolation properties for perf
            - vhost-user = (confusing) actually again it's userspace handling of virtqueues. but now a __different__ process (not the hypervisor) gets to consume the virtqueues. example is vhost-user-fs served by virtiofsd
            - vhost-mdev = idk, skipping this
            - vDSA = another vhost backend (vhost-vdpa), which is a standard interface for __devices__ to implement virtqueue ops. it's like hardware building in support for the virtio interface instead of its own driver interface
            - VDUSE = idk some confusing bytedance thing
    - ReDMArk (RDMA security)
        - The RDMA spec has access tokens for isolation / prevent unintended access, which are only sent over plaintext over the network. Unfortunately the network is not secure. IPsec for RoCE recently became available, but IPsec doesn't support Infiniband (uh oh).
            - Also IPsec obviously has throughput limitations since it costs CPU to do the encryption. Would affect achievable throughput.
        - This paper focuses on IB and RoCE, the two most widely used interconnects.
        - RoCEv1 has an IB header encapsulated in Ethernet, while RoCEv2 relies on UDP/IP framing, in some sense RoCEv2 wire protocol "goes over UDP."
        - Interesting description of adversaries: on a different host (issue normal messages), a privileged injector of forged messages, and someone who can actually listen to traffic on the path between victim and service.
        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fekzhang%2Fuu8qjOp4YP.png?alt=media&token=a3b5e463-2c32-4c5d-8411-023c1f076bed)
        - All RDMA read/write requests need an access key `rkey` negotiated by peers, this is checked by the NIC itself and can't be disabled. But there's not much entropy it seems, attackers can guess this value.
        - It goes over various attacks: DoS over QP exhaustion (24-bit number), unauthorized access via packet fabrication, etc.
        - Azure has cross-datacenter region RDMA? wtf? https://www.youtube.com/watch?v=Dcq_AwnfArI
